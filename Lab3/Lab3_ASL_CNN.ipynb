{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab3_ASL_CNN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Convolutional Neural Networks"
      ],
      "metadata": {
        "id": "3NYd7hOiSoti"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pada lab sebelumnya, telah dibuat dan ditrain simpel model untuk klasifikasi citra ASL. Model meliki akurasi yang tinggi pada training data, tetapi untuk validation data tidak perform sebaik di training data. Pada lab ini akan dibuat model cnn yang sangat bagus untuk klasifikasi citra"
      ],
      "metadata": {
        "id": "MCd2TrINSt92"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Objectives\n"
      ],
      "metadata": {
        "id": "9LZFXMLNTNP2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Prepare data untuk CNN\n",
        "*   Buat CNN model\n",
        "*   Train CNN model dan mengamati performanya\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xauEWx6DTR1S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Prepare Data"
      ],
      "metadata": {
        "id": "DUynjSyfTkWa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "XL5kUOfXRsYw"
      },
      "outputs": [],
      "source": [
        "import tensorflow.keras as keras\n",
        "import pandas as pd\n",
        "\n",
        "# load data dari CSV files\n",
        "train_df = pd.read_csv(\"/content/sign_mnist_train.csv\")\n",
        "valid_df = pd.read_csv(\"/content/sign_mnist_valid.csv\")\n",
        "\n",
        "# extract nilai target/label\n",
        "y_train = train_df['label']\n",
        "y_valid = valid_df['label']\n",
        "del train_df['label']\n",
        "del valid_df['label']\n",
        "\n",
        "# ambil nilai image data\n",
        "x_train = train_df.values\n",
        "x_valid = valid_df.values\n",
        "\n",
        "# ubah nilai target/label ke categorical\n",
        "num_classes = 24\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_valid = keras.utils.to_categorical(y_valid, num_classes)\n",
        "\n",
        "# normalize image data\n",
        "x_train = x_train / 255\n",
        "x_valid = x_valid / 255"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reshaping images data untuk CNN model\n",
        "\n",
        "Pada lab sebelumnya, image data dalam format 1d array 784 pixels. Pada format ini, kita tidak memiliki semua informasi mengenai pixel-pixel mana yang berdekatan satu sama lain. Karena ini, kita tidak dapat melakukan convolution untuk detect features penting"
      ],
      "metadata": {
        "id": "At6xNr-IWNUH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape)\n",
        "print(x_valid.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMw29PRASs1R",
        "outputId": "5ec34ffe-c841-42bf-976b-3b2bb457da70"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(27455, 784)\n",
            "(7172, 784)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reshape dataset kedalam format 28x28 pixel. Untuk layer convolutional pertama dari model, perlu tidak hanya height dan width dari citra, tetapi juga jumlah color channels. Karena citra merupakan grayscale, maka hanya memiliki 1 color channel\n",
        "\n",
        "Oleh karena itu, perlu konversi dari shape (27455, 784) menjadi (27455, 28, 28, 1)."
      ],
      "metadata": {
        "id": "WDoS0NqFXb1y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# nilai -1 pada argumen pertama jumlah citra tetap sama dengan citra awal\n",
        "x_train = x_train.reshape(-1, 28, 28, 1)\n",
        "x_valid = x_valid.reshape(-1, 28, 28, 1)"
      ],
      "metadata": {
        "id": "8-YO_meaXTDX"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dMGNH6ktZJlr",
        "outputId": "d0d41e6d-224e-491a-a26d-f67ba2626b9d"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(27455, 28, 28, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_valid.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ar9jhES6ZLZg",
        "outputId": "6bea350d-d635-4bd7-85ce-b5c694ef0a06"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7172, 28, 28, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94KtTPBbZNTw",
        "outputId": "128fbce2-320b-48b3-af8b-4b0c9243fa51"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebWHud9zZPs1",
        "outputId": "e032da0e-5ad7-4b5b-ec4d-4fc978e932d3"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(24,)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Create a CNN Model"
      ],
      "metadata": {
        "id": "nmhnJ-JcZaSy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import (\n",
        "    Dense,\n",
        "    Conv2D,\n",
        "    MaxPool2D,\n",
        "    Flatten,\n",
        "    Dropout,\n",
        "    BatchNormalization,\n",
        ")\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(75, (3, 3), strides=1, padding=\"same\", activation=\"relu\", \n",
        "                 input_shape=(28, 28, 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool2D((2, 2), strides=2, padding=\"same\"))\n",
        "model.add(Conv2D(50, (3, 3), strides=1, padding=\"same\", activation=\"relu\"))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool2D((2, 2), strides=2, padding=\"same\"))\n",
        "model.add(Conv2D(25, (3, 3), strides=1, padding=\"same\", activation=\"relu\"))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool2D((2, 2), strides=2, padding=\"same\"))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units=512, activation=\"relu\"))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(units=num_classes, activation=\"softmax\"))"
      ],
      "metadata": {
        "id": "s-QNJemcZeud"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conv2D merupakan 2D convolutional layers. Convolution merupakan perkalian antara antara filter/kernel dengan citra. Convolution dilakukan untuk detect feature2 yang penting untuk klasifikasi. Earlier convolution akan detect simpel feature seperti garis, later convolution akan detect feature yang lebih kompleks.\n",
        "\n",
        "model.add(Conv2D(75, (3, 3), strides=1, padding=\"same\", activation=\"relu\",\n",
        "                 input_shape=(28, 28, 1)))\n",
        "\n",
        "75 merupakan jumlah filter yang akan dipelajari. (3,3) merupakan ukuran filter, strides merujuk ke seberaja jauh cel filter akan digeser ketika proses convolution. padding=\"same\" akan memastikan filter diterapkan ke semua nilai dari input, output image dari convolution akan memiliki size yang sama dengan input image (untuk strides=1)"
      ],
      "metadata": {
        "id": "TFznE5RKkMdQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Batch Normalization merupakan layer yang menormalize inputnya, menerapkan transformasi yang mempertahankan mean dari output dekat ke 0 dan standard deviation output dekat ke 1. Ini berguna untuk menstabilkan proses learning dan secara dramatis mengurangi jumlah training epochs yang diperlukan untuk train model."
      ],
      "metadata": {
        "id": "EqL6_Azgn0_B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "MaxPool2D merupakan Max Pooling layer yang berguna untuk mengurangi resolusi dari citra. Hal ini dilakukan dengan menaruh window pada citra kemudian mengambil nilai maksimalnya.\n",
        "\n",
        "model.add(MaxPool2D((2, 2), strides=2, padding=\"same\"))\n",
        "\n",
        "(2,2) merupakan ukuran window"
      ],
      "metadata": {
        "id": "WwBXtbsood-j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dropout merupakan teknik yang digunakan untuk mencegah overfitting. Dropout akan memilih subset neuoron secara random kemudian mematikkan neuron tersebut, sehingga mereka tidak bisa learn (berpartisipasi dalam forward dan backward propagation). Hal ini dilakukan untuk memastikan model robust, tidak overreliance (sangat bergantung) pada input atau neuron tertentu.\n",
        "\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "0.2 merupakan rate dropout. 0 berarti tidak ada neuron yang dimatikan, 1 semua neuron dimatikan"
      ],
      "metadata": {
        "id": "shx2y49HpYn3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Flatten takes output dari satu layer (multidimensional), kemudian flatten/unroll kedalam 1 dimensional array. Hasilnya disebut feature vector dan akan terhubung dengan final cllasification layer"
      ],
      "metadata": {
        "id": "FPSYe5iVqyuO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dense\n",
        "\n",
        "dense layer pertama (512 units) takes feature vector sebagai input dan akan mempelajari feature mana yang akan berkontribusi untuk particular classification. dense layer kedua (24 units) merupakan final classification layer yang menghasilkan prediksi dari model dalam bentuk probabilitas (karena softmax activation func.)"
      ],
      "metadata": {
        "id": "APnybjqjrKQS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFCbg9JubFY-",
        "outputId": "5bc15931-7d4d-4e32-a89b-a76ff1ef7176"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_9 (Conv2D)           (None, 28, 28, 75)        750       \n",
            "                                                                 \n",
            " batch_normalization_9 (Batc  (None, 28, 28, 75)       300       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_9 (MaxPooling  (None, 14, 14, 75)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 14, 14, 50)        33800     \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 14, 14, 50)        0         \n",
            "                                                                 \n",
            " batch_normalization_10 (Bat  (None, 14, 14, 50)       200       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_10 (MaxPoolin  (None, 7, 7, 50)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 7, 7, 25)          11275     \n",
            "                                                                 \n",
            " batch_normalization_11 (Bat  (None, 7, 7, 25)         100       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_11 (MaxPoolin  (None, 4, 4, 25)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 400)               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 512)               205312    \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 24)                12312     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 264,049\n",
            "Trainable params: 263,749\n",
            "Non-trainable params: 300\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dari model summary diatas, ada 300 non-trainable paramas karena terdapat beberapa neuron yang kita matikan"
      ],
      "metadata": {
        "id": "z8H_sO1drykK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# compile the model\n",
        "model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "RQrzOpm2sPnT"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Train the Model"
      ],
      "metadata": {
        "id": "ym7sfMGJr6UL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train, epochs=20, verbose=1,\n",
        "          validation_data=(x_valid, y_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ZfbYn4Xro6e",
        "outputId": "8af98f13-f145-42c4-c92e-3ca346680759"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "858/858 [==============================] - 116s 131ms/step - loss: 0.3035 - accuracy: 0.9073 - val_loss: 0.2254 - val_accuracy: 0.9140\n",
            "Epoch 2/20\n",
            "858/858 [==============================] - 110s 128ms/step - loss: 0.0186 - accuracy: 0.9935 - val_loss: 0.5520 - val_accuracy: 0.8660\n",
            "Epoch 3/20\n",
            "858/858 [==============================] - 109s 127ms/step - loss: 0.0110 - accuracy: 0.9962 - val_loss: 0.2878 - val_accuracy: 0.9381\n",
            "Epoch 4/20\n",
            "858/858 [==============================] - 112s 130ms/step - loss: 0.0071 - accuracy: 0.9980 - val_loss: 0.2381 - val_accuracy: 0.9385\n",
            "Epoch 5/20\n",
            "858/858 [==============================] - 112s 130ms/step - loss: 0.0071 - accuracy: 0.9979 - val_loss: 0.2643 - val_accuracy: 0.9494\n",
            "Epoch 6/20\n",
            "858/858 [==============================] - 111s 129ms/step - loss: 0.0043 - accuracy: 0.9986 - val_loss: 0.2316 - val_accuracy: 0.9516\n",
            "Epoch 7/20\n",
            "858/858 [==============================] - 111s 130ms/step - loss: 0.0040 - accuracy: 0.9989 - val_loss: 0.2097 - val_accuracy: 0.9572\n",
            "Epoch 8/20\n",
            "858/858 [==============================] - 109s 127ms/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.1472 - val_accuracy: 0.9643\n",
            "Epoch 9/20\n",
            "858/858 [==============================] - 111s 129ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.8224 - val_accuracy: 0.8529\n",
            "Epoch 10/20\n",
            "858/858 [==============================] - 110s 128ms/step - loss: 0.0028 - accuracy: 0.9993 - val_loss: 0.2762 - val_accuracy: 0.9551\n",
            "Epoch 11/20\n",
            "858/858 [==============================] - 110s 128ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.2740 - val_accuracy: 0.9571\n",
            "Epoch 12/20\n",
            "858/858 [==============================] - 111s 129ms/step - loss: 0.0020 - accuracy: 0.9996 - val_loss: 0.3877 - val_accuracy: 0.9527\n",
            "Epoch 13/20\n",
            "858/858 [==============================] - 111s 129ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.3046 - val_accuracy: 0.9558\n",
            "Epoch 14/20\n",
            "858/858 [==============================] - 111s 129ms/step - loss: 0.0020 - accuracy: 0.9997 - val_loss: 0.5011 - val_accuracy: 0.9255\n",
            "Epoch 15/20\n",
            "858/858 [==============================] - 116s 135ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.3157 - val_accuracy: 0.9594\n",
            "Epoch 16/20\n",
            "858/858 [==============================] - 112s 130ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.3821 - val_accuracy: 0.9589\n",
            "Epoch 17/20\n",
            "858/858 [==============================] - 112s 130ms/step - loss: 7.1112e-04 - accuracy: 0.9997 - val_loss: 0.6132 - val_accuracy: 0.9346\n",
            "Epoch 18/20\n",
            "858/858 [==============================] - 107s 125ms/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.3091 - val_accuracy: 0.9591\n",
            "Epoch 19/20\n",
            "858/858 [==============================] - 108s 126ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.3363 - val_accuracy: 0.9658\n",
            "Epoch 20/20\n",
            "858/858 [==============================] - 107s 125ms/step - loss: 7.6064e-04 - accuracy: 0.9997 - val_loss: 0.3213 - val_accuracy: 0.9671\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f61b2977b90>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Terlihat model sudah meningkat secara signifikan. Trining accuracy sangat tinggi, dan validation accuracy telah meningkat juga. Akan tetapi validation accuracy masih melompat-lompat yang menandandakan model masih belum bisa melakukan generalisasi secara sempurna. Lab selanjutnya akan mencoba mengatasi permasalahan ini"
      ],
      "metadata": {
        "id": "TSZIlvka-gwJ"
      }
    }
  ]
}